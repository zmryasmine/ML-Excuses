{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from tensorflow.keras.metrics import Recall, AUC\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc, precision_score, recall_score, f1_score, accuracy_score, confusion_matrix\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import mlflow.keras\n",
    "from mlflow.models import infer_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000,)\n",
      "[3 3 3 3 3 3 3 3 3 3]\n"
     ]
    }
   ],
   "source": [
    "metadata = pd.read_csv('dataset/balanced_metadata.csv')\n",
    "image_folder = 'dataset/balanced_dataset/'\n",
    "images = []\n",
    "labels = []\n",
    "for i, row in metadata.iterrows():\n",
    "    img_path = os.path.join(image_folder, row['image_name'])\n",
    "    img = load_img(img_path, target_size=(128, 128))\n",
    "    images.append(img_to_array(img))\n",
    "    labels.append(row['target'])\n",
    "\n",
    "images = np.array(images) / 255.0  # Normalisation\n",
    "labels = np.array(labels)\n",
    "print(labels.shape)\n",
    "print(labels[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 128, 128, 3)\n",
      "(8000, 4)\n"
     ]
    }
   ],
   "source": [
    "labels = to_categorical(labels, num_classes=4)\n",
    "print(images.shape)  \n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn_model(input_shape=(128, 128, 3), num_classes=4, optimizer='adam',\n",
    "                    dropout_rate=0.5, activation='relu', filters=32, kernel_size=(3, 3)):\n",
    "    model = Sequential()\n",
    "\n",
    "    # Première couche convolutionnelle\n",
    "    model.add(Conv2D(filters, kernel_size, activation=activation, input_shape=input_shape))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "    # Deuxième couche convolutionnelle\n",
    "    model.add(Conv2D(filters * 2, kernel_size, activation=activation))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "    # Troisième couche convolutionnelle\n",
    "    model.add(Conv2D(filters * 4, kernel_size, activation=activation))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "    # Aplatir les résultats des couches précédentes\n",
    "    model.add(Flatten())\n",
    "\n",
    "    # Couches entièrement connectées\n",
    "    model.add(Dense(128, activation=activation))\n",
    "    model.add(Dropout(dropout_rate))  # Dropout pour éviter l'overfitting\n",
    "    model.add(Dense(num_classes, activation='softmax'))  # Classification multi-classe\n",
    "\n",
    "    # Choisir l'optimiseur basé sur l'argument\n",
    "    if optimizer == 'adam':\n",
    "        optimizer_instance = Adam()\n",
    "    elif optimizer == 'sgd':\n",
    "        optimizer_instance = SGD()\n",
    "    elif optimizer == 'rmsprop':\n",
    "        optimizer_instance = RMSprop()\n",
    "\n",
    "    # Compiler le modèle avec les métriques supplémentaires\n",
    "    model.compile(optimizer=optimizer_instance, \n",
    "                  loss='categorical_crossentropy', \n",
    "                  metrics=['accuracy', Recall(), AUC()])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choix des paramètres\n",
    "param_grid = {\n",
    "    'optimizer': 'adam',  # Optimiseur à tester\n",
    "    'dropout_rate': [0.3, 0.5],  # Taux de dropout\n",
    "    'activation': 'relu',  # Fonction d'activation des couches\n",
    "    'filters': [16, 32],  # Nombre de filtres dans les couches convolutionnelles\n",
    "    'kernel_size': (3, 3),  # Taille des noyaux de convolution\n",
    "    'batch_size': 32,  # Taille des mini-batchs\n",
    "    'epochs': 10  # Nombre d'époques\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- run on terminal **mlflow server --host 127.0.0.1 --port 5000**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:5000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- run on terminal **mlflow ui**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/344762819335167390', creation_time=1733865490229, experiment_id='344762819335167390', last_update_time=1733865490229, lifecycle_stage='active', name='Brain_Tumor_Classification', tags={}>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(\"Brain_Tumor_Classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment ID: 344762819335167390\n"
     ]
    }
   ],
   "source": [
    "experiment = mlflow.get_experiment_by_name(\"Brain_Tumor_Classification\")\n",
    "experiment_id = experiment.experiment_id\n",
    "\n",
    "print(f\"Experiment ID: {experiment_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramètres pour la validation croisée\n",
    "num_folds = 3\n",
    "cv = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting experiment 1 with parameters: {'filters': 16, 'kernel_size': (5, 5), 'dropout_rate': 0.3, 'batch_size': 32, 'epochs': 10, 'optimizer': 'adam'}\n",
      "Fold 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Documents\\GitHub\\ML-Excuses\\env\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 92ms/step - accuracy: 0.4648 - auc: 0.7466 - loss: 1.1354 - recall: 0.2081 - val_accuracy: 0.6749 - val_auc: 0.8819 - val_loss: 0.8394 - val_recall: 0.5975\n",
      "Epoch 2/10\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 92ms/step - accuracy: 0.7185 - auc: 0.9174 - loss: 0.6870 - recall: 0.6504 - val_accuracy: 0.7668 - val_auc: 0.9446 - val_loss: 0.5636 - val_recall: 0.7422\n",
      "Epoch 3/10\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 106ms/step - accuracy: 0.8136 - auc: 0.9592 - loss: 0.4786 - recall: 0.7838 - val_accuracy: 0.8149 - val_auc: 0.9605 - val_loss: 0.4682 - val_recall: 0.7944\n",
      "Epoch 4/10\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 98ms/step - accuracy: 0.8321 - auc: 0.9708 - loss: 0.4012 - recall: 0.8176 - val_accuracy: 0.8582 - val_auc: 0.9732 - val_loss: 0.3780 - val_recall: 0.8453\n",
      "Epoch 5/10\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 99ms/step - accuracy: 0.8901 - auc: 0.9841 - loss: 0.2964 - recall: 0.8750 - val_accuracy: 0.8770 - val_auc: 0.9801 - val_loss: 0.3245 - val_recall: 0.8682\n",
      "Epoch 6/10\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 104ms/step - accuracy: 0.9063 - auc: 0.9882 - loss: 0.2486 - recall: 0.8972 - val_accuracy: 0.8905 - val_auc: 0.9813 - val_loss: 0.3103 - val_recall: 0.8828\n",
      "Epoch 7/10\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 107ms/step - accuracy: 0.9288 - auc: 0.9926 - loss: 0.1866 - recall: 0.9200 - val_accuracy: 0.8881 - val_auc: 0.9794 - val_loss: 0.3358 - val_recall: 0.8822\n",
      "Epoch 8/10\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 101ms/step - accuracy: 0.9484 - auc: 0.9968 - loss: 0.1365 - recall: 0.9438 - val_accuracy: 0.8957 - val_auc: 0.9820 - val_loss: 0.3048 - val_recall: 0.8910\n",
      "Epoch 9/10\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 100ms/step - accuracy: 0.9595 - auc: 0.9976 - loss: 0.1111 - recall: 0.9575 - val_accuracy: 0.9104 - val_auc: 0.9812 - val_loss: 0.3227 - val_recall: 0.9086\n",
      "Epoch 10/10\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 100ms/step - accuracy: 0.9718 - auc: 0.9985 - loss: 0.0849 - recall: 0.9706 - val_accuracy: 0.9098 - val_auc: 0.9820 - val_loss: 0.3145 - val_recall: 0.9080\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "Fold 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Documents\\GitHub\\ML-Excuses\\env\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - accuracy: 0.5288 - auc_1: 0.7869 - loss: 1.0616 - recall_1: 0.2954 - val_accuracy: 0.7680 - val_auc_1: 0.9383 - val_loss: 0.6144 - val_recall_1: 0.6749\n",
      "Epoch 2/10\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 104ms/step - accuracy: 0.7642 - auc_1: 0.9344 - loss: 0.6153 - recall_1: 0.6983 - val_accuracy: 0.7844 - val_auc_1: 0.9451 - val_loss: 0.5580 - val_recall_1: 0.7581\n",
      "Epoch 3/10\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 102ms/step - accuracy: 0.8103 - auc_1: 0.9626 - loss: 0.4611 - recall_1: 0.7856 - val_accuracy: 0.7803 - val_auc_1: 0.9527 - val_loss: 0.5171 - val_recall_1: 0.7545\n",
      "Epoch 4/10\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 102ms/step - accuracy: 0.8800 - auc_1: 0.9804 - loss: 0.3256 - recall_1: 0.8674 - val_accuracy: 0.8705 - val_auc_1: 0.9759 - val_loss: 0.3680 - val_recall_1: 0.8629\n",
      "Epoch 5/10\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 103ms/step - accuracy: 0.9096 - auc_1: 0.9899 - loss: 0.2343 - recall_1: 0.8995 - val_accuracy: 0.8799 - val_auc_1: 0.9785 - val_loss: 0.3457 - val_recall_1: 0.8670\n",
      "Epoch 6/10\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 105ms/step - accuracy: 0.9378 - auc_1: 0.9937 - loss: 0.1823 - recall_1: 0.9337 - val_accuracy: 0.8916 - val_auc_1: 0.9792 - val_loss: 0.3448 - val_recall_1: 0.8893\n",
      "Epoch 7/10\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 109ms/step - accuracy: 0.9632 - auc_1: 0.9973 - loss: 0.1128 - recall_1: 0.9616 - val_accuracy: 0.8987 - val_auc_1: 0.9800 - val_loss: 0.3490 - val_recall_1: 0.8928\n",
      "Epoch 8/10\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 106ms/step - accuracy: 0.9692 - auc_1: 0.9982 - loss: 0.0893 - recall_1: 0.9682 - val_accuracy: 0.9110 - val_auc_1: 0.9823 - val_loss: 0.3259 - val_recall_1: 0.9069\n",
      "Epoch 9/10\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 109ms/step - accuracy: 0.9772 - auc_1: 0.9990 - loss: 0.0687 - recall_1: 0.9764 - val_accuracy: 0.8840 - val_auc_1: 0.9729 - val_loss: 0.4309 - val_recall_1: 0.8793\n",
      "Epoch 10/10\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 109ms/step - accuracy: 0.9736 - auc_1: 0.9987 - loss: 0.0817 - recall_1: 0.9711 - val_accuracy: 0.8799 - val_auc_1: 0.9755 - val_loss: 0.5032 - val_recall_1: 0.8787\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step\n",
      "Fold 3/3\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Documents\\GitHub\\ML-Excuses\\env\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 113ms/step - accuracy: 0.4840 - auc_2: 0.7587 - loss: 1.1114 - recall_2: 0.2403 - val_accuracy: 0.7128 - val_auc_2: 0.9185 - val_loss: 0.6911 - val_recall_2: 0.6342\n",
      "Epoch 2/10\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 109ms/step - accuracy: 0.7417 - auc_2: 0.9280 - loss: 0.6448 - recall_2: 0.6751 - val_accuracy: 0.7989 - val_auc_2: 0.9528 - val_loss: 0.5520 - val_recall_2: 0.7239\n",
      "Epoch 3/10\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 114ms/step - accuracy: 0.7895 - auc_2: 0.9499 - loss: 0.5334 - recall_2: 0.7490 - val_accuracy: 0.8118 - val_auc_2: 0.9621 - val_loss: 0.4632 - val_recall_2: 0.7872\n",
      "Epoch 4/10\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 113ms/step - accuracy: 0.8388 - auc_2: 0.9705 - loss: 0.4027 - recall_2: 0.8191 - val_accuracy: 0.8306 - val_auc_2: 0.9654 - val_loss: 0.4453 - val_recall_2: 0.8154\n",
      "Epoch 5/10\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 114ms/step - accuracy: 0.8752 - auc_2: 0.9790 - loss: 0.3388 - recall_2: 0.8558 - val_accuracy: 0.8675 - val_auc_2: 0.9745 - val_loss: 0.3741 - val_recall_2: 0.8511\n",
      "Epoch 6/10\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 118ms/step - accuracy: 0.8845 - auc_2: 0.9851 - loss: 0.2856 - recall_2: 0.8709 - val_accuracy: 0.8863 - val_auc_2: 0.9808 - val_loss: 0.3262 - val_recall_2: 0.8787\n",
      "Epoch 7/10\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 120ms/step - accuracy: 0.9392 - auc_2: 0.9945 - loss: 0.1688 - recall_2: 0.9313 - val_accuracy: 0.8986 - val_auc_2: 0.9843 - val_loss: 0.2999 - val_recall_2: 0.8957\n",
      "Epoch 8/10\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 117ms/step - accuracy: 0.9495 - auc_2: 0.9963 - loss: 0.1389 - recall_2: 0.9477 - val_accuracy: 0.8962 - val_auc_2: 0.9799 - val_loss: 0.3481 - val_recall_2: 0.8945\n",
      "Epoch 9/10\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 126ms/step - accuracy: 0.9573 - auc_2: 0.9973 - loss: 0.1220 - recall_2: 0.9567 - val_accuracy: 0.9074 - val_auc_2: 0.9842 - val_loss: 0.3117 - val_recall_2: 0.9056\n",
      "Epoch 10/10\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 111ms/step - accuracy: 0.9663 - auc_2: 0.9982 - loss: 0.0958 - recall_2: 0.9634 - val_accuracy: 0.9115 - val_auc_2: 0.9834 - val_loss: 0.3245 - val_recall_2: 0.9097\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/10 23:06:42 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2024/12/10 23:06:48 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "nb = 0\n",
    "for filters in param_grid['filters']:\n",
    "        for dropout_rate in param_grid['dropout_rate']:\n",
    "                    nb = nb + 1\n",
    "\n",
    "                    # Paramètres du modèle\n",
    "                    params = {\n",
    "                        'filters': filters,\n",
    "                        'kernel_size': param_grid['kernel_size'],\n",
    "                        'dropout_rate': dropout_rate,\n",
    "                        'batch_size': param_grid['batch_size'],\n",
    "                        'epochs': param_grid['epochs'],\n",
    "                        'optimizer': param_grid['optimizer']\n",
    "                    }\n",
    "                    print(f\"Starting experiment {nb} with parameters: {params}\")\n",
    "\n",
    "                    with mlflow.start_run() as run:\n",
    "                        mlflow.set_tag(\"mlflow.runName\", f\"CNN : Experiment {nb}\")\n",
    "                        mlflow.set_tag(\"Experiment Info\", f\"Experiment {nb} for NN with parameters : {params}\")\n",
    "                        mlflow.log_params(params)\n",
    "\n",
    "                        fold_metrics = []\n",
    "                        for fold, (train_idx, val_idx) in enumerate(cv.split(X_train, np.argmax(y_train, axis=1))):\n",
    "                            print(f\"Fold {fold + 1}/{num_folds}\")\n",
    "                            \n",
    "                            X_fold_train, X_fold_val = X_train[train_idx], X_train[val_idx]\n",
    "                            y_fold_train, y_fold_val = y_train[train_idx], y_train[val_idx]\n",
    "\n",
    "                            model = build_cnn_model(\n",
    "                                input_shape=(128, 128, 3),\n",
    "                                num_classes=4,\n",
    "                                optimizer=params['optimizer'],\n",
    "                                dropout_rate=params['dropout_rate'],\n",
    "                                activation='relu',\n",
    "                                filters=params['filters'],\n",
    "                                kernel_size=params['kernel_size']\n",
    "                            )\n",
    "                            early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "                            history = model.fit(\n",
    "                                X_fold_train, y_fold_train,\n",
    "                                validation_data=(X_fold_val, y_fold_val),\n",
    "                                batch_size=params['batch_size'],\n",
    "                                epochs=params['epochs'],\n",
    "                                callbacks=[early_stopping],\n",
    "                                verbose=1\n",
    "                            )\n",
    "\n",
    "                            # Prédictions et métriques sur le fold\n",
    "                            y_val_pred = model.predict(X_fold_val)\n",
    "                            y_val_pred_classes = np.argmax(y_val_pred, axis=1)\n",
    "                            y_val_actual_classes = np.argmax(y_fold_val, axis=1)\n",
    "\n",
    "                            accuracy = accuracy_score(y_val_actual_classes, y_val_pred_classes)\n",
    "                            precision = precision_score(y_val_actual_classes, y_val_pred_classes, average='weighted')\n",
    "                            recall = recall_score(y_val_actual_classes, y_val_pred_classes, average='weighted')\n",
    "                            f1 = f1_score(y_val_actual_classes, y_val_pred_classes, average='weighted')\n",
    "                            auc_roc = roc_auc_score(y_fold_val, y_val_pred, multi_class='ovr')\n",
    "\n",
    "                            fold_metrics.append({\n",
    "                                'accuracy': accuracy,\n",
    "                                'precision': precision,\n",
    "                                'recall': recall,\n",
    "                                'f1': f1,\n",
    "                                'auc_roc': auc_roc\n",
    "                            })\n",
    "\n",
    "                            # Logging des métriques pour chaque fold\n",
    "                            mlflow.log_metric(f\"fold_{fold + 1}_accuracy\", accuracy)\n",
    "                            mlflow.log_metric(f\"fold_{fold + 1}_precision\", precision)\n",
    "                            mlflow.log_metric(f\"fold_{fold + 1}_recall\", recall)\n",
    "                            mlflow.log_metric(f\"fold_{fold + 1}_f1\", f1)\n",
    "                            mlflow.log_metric(f\"fold_{fold + 1}_auc_roc\", auc_roc)\n",
    "                           # Moyennes des métriques sur tous les folds\n",
    "                        avg_accuracy = np.mean([m['accuracy'] for m in fold_metrics])\n",
    "                        avg_precision = np.mean([m['precision'] for m in fold_metrics])\n",
    "                        avg_recall = np.mean([m['recall'] for m in fold_metrics])\n",
    "                        avg_f1 = np.mean([m['f1'] for m in fold_metrics])\n",
    "                        avg_auc_roc = np.mean([m['auc_roc'] for m in fold_metrics])\n",
    "\n",
    "                        mlflow.log_metric(\"avg_accuracy\", avg_accuracy)\n",
    "                        mlflow.log_metric(\"avg_precision\", avg_precision)\n",
    "                        mlflow.log_metric(\"avg_recall\", avg_recall)\n",
    "                        mlflow.log_metric(\"avg_f1\", avg_f1)\n",
    "                        mlflow.log_metric(\"avg_auc_roc\", avg_auc_roc)\n",
    "\n",
    "                        # Prédictions finales sur X_test\n",
    "                        y_test_pred = model.predict(X_test)\n",
    "                        y_test_pred_classes = np.argmax(y_test_pred, axis=1)\n",
    "                        y_test_actual_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "                        # Calcul des métriques sur le test\n",
    "                        test_accuracy = accuracy_score(y_test_actual_classes, y_test_pred_classes)\n",
    "                        test_precision = precision_score(y_test_actual_classes, y_test_pred_classes, average='weighted')\n",
    "                        test_recall = recall_score(y_test_actual_classes, y_test_pred_classes, average='weighted')\n",
    "                        test_f1 = f1_score(y_test_actual_classes, y_test_pred_classes, average='weighted')\n",
    "\n",
    "                        mlflow.log_metric(\"test_accuracy\", test_accuracy)\n",
    "                        mlflow.log_metric(\"test_precision\", test_precision)\n",
    "                        mlflow.log_metric(\"test_recall\", test_recall)\n",
    "                        mlflow.log_metric(\"test_f1\", test_f1)\n",
    "\n",
    "                        predictions_df = pd.DataFrame({\"Actual\" : y_test_actual_classes, \"Predicted\": y_test_pred_classes})\n",
    "                        predictions_csv_path = \"tmp/predictions.csv\"\n",
    "                        predictions_df.to_csv(predictions_csv_path, index=False)\n",
    "                        mlflow.log_artifact(predictions_csv_path, artifact_path=\"predictions\")\n",
    "\n",
    "                        # Matrice de confusion\n",
    "                        matrix = confusion_matrix(y_test_actual_classes, y_test_pred_classes)\n",
    "                        plt.figure(figsize=(8, 6))\n",
    "                        sns.heatmap(matrix, annot=True, fmt='d', cmap='Blues')\n",
    "                        plt.title(\"Confusion Matrix\")\n",
    "                        cf_matrix_path = \"tmp/confusion_matrix.png\"\n",
    "                        plt.savefig(cf_matrix_path)\n",
    "                        plt.close()\n",
    "                        mlflow.log_artifact(cf_matrix_path, artifact_path=\"cf_matrix\")\n",
    "\n",
    "                        # Courbe ROC AUC\n",
    "                        fpr, tpr, _ = roc_curve(y_test.ravel(), y_test_pred.ravel())\n",
    "                        roc_auc = auc(fpr, tpr)\n",
    "\n",
    "                        plt.figure()\n",
    "                        plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "                        plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "                        plt.xlabel(\"False Positive Rate\")\n",
    "                        plt.ylabel(\"True Positive Rate\")\n",
    "                        plt.title(\"Receiver Operating Characteristic\")\n",
    "                        plt.legend(loc=\"lower right\")\n",
    "                        roc_curve_path = \"tmp/roc_curve.png\"\n",
    "                        plt.savefig(roc_curve_path)\n",
    "                        plt.close()\n",
    "                        mlflow.log_artifact(roc_curve_path, artifact_path=\"roc_curve\")\n",
    "\n",
    "                        # Enregistrement du modèle final\n",
    "                        mlflow.keras.log_model(model, \"cnn_model\")\n",
    "                        signature = infer_signature(X_train, model.predict(X_train))\n",
    "                        model_info = mlflow.sklearn.log_model(\n",
    "                            sk_model=model,\n",
    "                            artifact_path=\"cnn_model\",\n",
    "                            signature=signature,\n",
    "                            input_example=X_train[:1],\n",
    "                            registered_model_name=\"convolutional-neural-network\",\n",
    "                        )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML-Excuses",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

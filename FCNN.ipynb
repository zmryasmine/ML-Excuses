{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5793 - loss: 1.1578 - val_accuracy: 0.6825 - val_loss: 0.8023 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7206 - loss: 0.7068 - val_accuracy: 0.6756 - val_loss: 0.8224 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7652 - loss: 0.5973 - val_accuracy: 0.5150 - val_loss: 1.4886 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8110 - loss: 0.5011 - val_accuracy: 0.7069 - val_loss: 0.7364 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8047 - loss: 0.5103 - val_accuracy: 0.7575 - val_loss: 0.6671 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8165 - loss: 0.4771 - val_accuracy: 0.6750 - val_loss: 0.7900 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8125 - loss: 0.4857 - val_accuracy: 0.7394 - val_loss: 0.6779 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.8310 - loss: 0.4299 - val_accuracy: 0.6519 - val_loss: 1.4580 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8428 - loss: 0.4152 - val_accuracy: 0.7881 - val_loss: 0.5409 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8317 - loss: 0.4267 - val_accuracy: 0.7675 - val_loss: 0.5815 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8413 - loss: 0.4070 - val_accuracy: 0.6494 - val_loss: 1.0983 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8518 - loss: 0.4076 - val_accuracy: 0.8294 - val_loss: 0.4661 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8468 - loss: 0.4106 - val_accuracy: 0.8056 - val_loss: 0.4881 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8525 - loss: 0.3665 - val_accuracy: 0.7775 - val_loss: 0.6304 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8527 - loss: 0.3948 - val_accuracy: 0.8263 - val_loss: 0.5264 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8655 - loss: 0.3619 - val_accuracy: 0.8169 - val_loss: 0.4920 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m197/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8758 - loss: 0.3381\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8758 - loss: 0.3381 - val_accuracy: 0.7525 - val_loss: 0.6354 - learning_rate: 0.0010\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8343 - loss: 0.4600\n",
      "Test Accuracy: 82.94%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Directory for images\n",
    "image_dir = 'dataset/balanced_dataset'\n",
    "image_size = (64, 64)\n",
    "\n",
    "# Load and preprocess images\n",
    "def load_images_and_labels(data, image_dir, image_size):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for _, row in data.iterrows():\n",
    "        image_path = os.path.join(image_dir, row['image_name'])\n",
    "        if os.path.exists(image_path):\n",
    "            img = load_img(image_path, target_size=image_size)\n",
    "            img_array = img_to_array(img) / 255.0\n",
    "            images.append(img_array)\n",
    "            labels.append(row['target'])\n",
    "        else:\n",
    "            print(f\"Image not found: {image_path}\")\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv('dataset/balanced_metadata.csv')\n",
    "images, labels = load_images_and_labels(data, image_dir, image_size)\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "num_classes = len(np.unique(labels))\n",
    "labels_one_hot = to_categorical(labels, num_classes)\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels_one_hot, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the optimised shallow neural network model\n",
    "model = Sequential([\n",
    "    Flatten(input_shape=image_size + (3,)),  # Flatten the input images\n",
    "    Dense(256, activation='relu'),          # First hidden layer\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),                           # Dropout for regularisation\n",
    "    Dense(128, activation='relu'),          # Second hidden layer\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),           # Third hidden layer\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(num_classes, activation='softmax')  # Output layer for classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Callbacks for better training\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, verbose=1)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    epochs=50,\n",
    "                    batch_size=32,\n",
    "                    callbacks=[early_stopping, lr_scheduler])\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
